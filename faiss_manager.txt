import numpy as np
from typing import List, Optional, Dict, Any
from pathlib import Path
import logging
from langchain.embeddings.base import Embeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CustomEmbeddings(Embeddings):
    """Production-ready embedding wrapper with FAISS integration."""
    
    def __init__(self, model_name: str = "textembedding-gecko"):
        try:
            self.connector = VertexAIConnector()
            self.model = self.connector.get_embedding_model(model_name)
            self._verify_embedding_function()
            logger.info(f"Initialized embeddings with model: {model_name}")
        except Exception as e:
            logger.error(f"Initialization failed: {str(e)}")
            raise

    def _verify_embedding_function(self):
        """Validate the embedding function on startup."""
        test_output = self.embed_documents(["test"])
        if not isinstance(test_output[0][0], float):
            raise ValueError("Embedding output must be List[List[float]]")

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """Batch embed documents with error handling."""
        if not texts:
            return []
            
        try:
            vectors = self.model.get_embeddings(texts)
            return self._ensure_float_vectors(vectors)
        except Exception as e:
            logger.error(f"Document embedding failed: {str(e)}")
            raise

    def embed_query(self, text: str) -> List[float]:
        """Embed a single query with error handling."""
        return self.embed_documents([text])[0]

    @staticmethod
    def _ensure_float_vectors(vectors) -> List[List[float]]:
        """Convert all outputs to List[List[float]]."""
        if isinstance(vectors, np.ndarray):
            return vectors.astype(float).tolist()
        return [[float(x) for x in vec] for vec in vectors]

    def create_faiss_index(
        self,
        texts: List[str],
        metadatas: Optional[List[dict]] = None,
        save_path: Optional[str] = None
    ) -> FAISS:
        """Create and optionally persist a FAISS index."""
        try:
            documents = [
                Document(page_content=text, metadata=metadata or {})
                for text, metadata in zip(texts, metadatas or [{}]*len(texts))
            ]
            
            vector_store = FAISS.from_documents(
                documents=documents,
                embedding=self,
            )
            
            if save_path:
                Path(save_path).mkdir(parents=True, exist_ok=True)
                vector_store.save_local(save_path)
                logger.info(f"Saved FAISS index to {save_path}")
            
            return vector_store
            
        except Exception as e:
            logger.error(f"FAISS index creation failed: {str(e)}")
            raise

    @classmethod
    def load_faiss_index(
        cls,
        folder_path: str,
        model_name: str = "textembedding-gecko"
    ) -> FAISS:
        """Load persisted FAISS index."""
        try:
            embeddings = cls(model_name)
            return FAISS.load_local(
                folder_path=folder_path,
                embeddings=embeddings,
                allow_dangerous_deserialization=True
            )
        except Exception as e:
            logger.error(f"Index loading failed: {str(e)}")
            raise