from flask import Flask, request, jsonify
from werkzeug.utils import secure_filename
import uuid
import os
from datetime import datetime
from document_processor import analyze_documents_async
import threading

app = Flask(__name__)

# Configuration
UPLOAD_DIR = "uploads"
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
ALLOWED_EXTENSIONS = {'.pdf', '.docx', '.txt'}
os.makedirs(UPLOAD_DIR, exist_ok=True)

# In-memory storage
tasks = {}
file_store = {}

@app.route('/upload', methods=['POST'])
def upload_file():
    """Secure file upload endpoint"""
    if 'file' not in request.files:
        return jsonify({"error": "No file provided"}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({"error": "Empty filename"}), 400
    
    if not allowed_file(file.filename):
        return jsonify({"error": "Unsupported file type"}), 400
    
    try:
        file_id = str(uuid.uuid4())
        filename = secure_filename(file.filename)
        file_path = os.path.join(UPLOAD_DIR, file_id)
        
        # Save file and metadata
        file.save(file_path)
        file_store[file_id] = {
            "original_name": filename,
            "upload_time": datetime.now().isoformat(),
            "size": os.path.getsize(file_path)
        }
        
        return jsonify({"file_id": file_id})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/analyze', methods=['POST'])
def analyze_documents():
    """Initiate document analysis"""
    data = request.get_json()
    if not data or 'file_ids' not in data:
        return jsonify({"error": "file_ids required"}), 400
    
    task_id = str(uuid.uuid4())
    tasks[task_id] = {
        "status": "queued",
        "created": datetime.now().isoformat()
    }
    
    # Start async processing
    thread = threading.Thread(
        target=analyze_documents_async,
        args=(task_id, data['file_ids'], tasks, file_store)
    )
    thread.start()
    
    return jsonify({
        "task_id": task_id,
        "status_url": f"/tasks/{task_id}"
    })

@app.route('/tasks/<task_id>', methods=['GET'])
def get_task_status(task_id):
    """Check analysis task status"""
    task = tasks.get(task_id)
    if not task:
        return jsonify({"error": "Task not found"}), 404
    
    response = {
        "task_id": task_id,
        "status": task["status"],
        "created": task["created"]
    }
    
    if task["status"] == "completed":
        response["result"] = task["result"]
    elif task["status"] == "failed":
        response["error"] = task.get("error", "Unknown error")
    
    return jsonify(response)

def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in {ext[1:] for ext in ALLOWED_EXTENSIONS}

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
	

====================================================================

from google.cloud import aiplatform
from google.api_core import retry
import pdfplumber
import docx
import os
import re
from datetime import datetime

# Initialize Vertex AI
aiplatform.init(project="your-gcp-project", location="us-central1")
model = aiplatform.GenerativeModel("gemini-pro")

@retry.Retry(
    initial=1.0,
    maximum=10.0,
    multiplier=2.0,
    deadline=60.0,
)
def generate_with_vertex(prompt: str) -> str:
    """Generate content with Vertex AI"""
    response = model.generate_content(prompt)
    return response.text

def extract_text(file_path: str) -> str:
    """Extract text from supported file types"""
    ext = os.path.splitext(file_path)[1].lower()
    
    try:
        if ext == '.pdf':
            with pdfplumber.open(file_path) as pdf:
                return "\n".join(page.extract_text() for page in pdf.pages if page.extract_text())
        elif ext == '.docx':
            doc = docx.Document(file_path)
            return "\n".join(para.text for para in doc.paragraphs)
        elif ext == '.txt':
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        return ""
    except Exception as e:
        raise ValueError(f"Error processing file: {str(e)}")

def parse_ai_response(text: str) -> dict:
    """Parse structured AI response"""
    try:
        parts = re.split(r'\n(?=\d\.)', text.strip())
        if len(parts) < 3:
            raise ValueError("Unexpected AI response format")
        
        return {
            "project_name": parts[0].replace("1. ", "").strip(),
            "description": parts[1].replace("2. ", "").strip(),
            "draft_content": "\n".join(parts[2:]).replace("3. ", "").strip()
        }
    except Exception as e:
        raise ValueError(f"Failed to parse AI response: {str(e)}")

def analyze_documents_async(task_id: str, file_ids: list, task_store: dict, file_store: dict):
    """Async document processing pipeline"""
    try:
        task_store[task_id]["status"] = "processing"
        task_store[task_id]["last_updated"] = datetime.now().isoformat()
        
        # 1. Extract text from documents
        documents_text = []
        for file_id in file_ids:
            if file_id not in file_store:
                continue
                
            file_path = os.path.join("uploads", file_id)
            if not os.path.exists(file_path):
                continue
                
            try:
                text = extract_text(file_path)
                if text:
                    documents_text.append(text)
            except Exception as e:
                print(f"Error processing {file_id}: {str(e)}")
        
        if not documents_text:
            raise ValueError("No extractable content found in documents")
        
        # 2. Generate with Vertex AI
        prompt = f"""Generate the following based on technical documents:
1. Project Name: <CamelCase technical name>
2. Description: <50-100 word concise description>
3. Requirements Outline:
### Functional Requirements
- <Key feature 1>
- <Key feature 2>

### Technical Specifications
```<appropriate language>
// Sample implementation
Document Content:
{" ".join(documents_text)[:10000]}"""

    ai_response = generate_with_vertex(prompt)
    result = parse_ai_response(ai_response)
    
    # 3. Store results
    task_store[task_id].update({
        "status": "completed",
        "result": {
            "project_name": result["project_name"],
            "description": result["description"],
            "draft_content": result["draft_content"]
        },
        "completed_at": datetime.now().isoformat()
    })
    
except Exception as e:
    task_store[task_id].update({
        "status": "failed",
        "error": str(e),
        "failed_at": datetime.now().isoformat()
    })